{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e851dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/xc/yz4w7wkj0sd7pg8d43gr8llw0000gn/T/ipykernel_3583/3824536991.py:29: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import csv\n",
    "\n",
    "# import the relevant functions from cnn functions\n",
    "from cnn_functions import prep_training_data, prep_test_data, show_logger_plot\n",
    "from cnn_functions import train_model, test_model, train_aug_gen_model\n",
    "\n",
    "# set the seed value\n",
    "seed = 42\n",
    "\n",
    "# set pythonhashseed to a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "\n",
    "# set the python pseudorandom number generator to a fixed value\n",
    "random.seed(seed)\n",
    "\n",
    "# set the numpy and tf pseudorandom number generator to a fixed value\n",
    "np.random.seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)\n",
    "\n",
    "# configure new session\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be901bd",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "#### The functions used in this files will be loaded from \"cnn_functions.py\"\n",
    "\n",
    "The code cell below contains the codes to do the following:\n",
    "- Read the csv files containing the file names and the labels\n",
    "- Load the images based on the file names read from the csv file\n",
    "- Prepare the training, validation and test data to be used for the cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4ab398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chanweiquan/miniforge3/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data for training and testing\n",
    "csv_folder = \"image-info-csv/\"\n",
    "train_csv_fname = f\"{csv_folder}train_refined.csv\"\n",
    "train_folder_name = \"train\"\n",
    "test_csv_fname = f\"{csv_folder}test_base.csv\"\n",
    "test_folder_name = \"test\"\n",
    "\n",
    "# initialise rescale value\n",
    "img_rescale = 1./255\n",
    "validation_split = 0.15\n",
    "reshaped_size=[224,224]\n",
    "\n",
    "# Generate the data for training and testing\n",
    "x_train, x_val, y_train, y_val, x_input_shape, output_layer = prep_training_data(train_csv_fname, train_folder_name\n",
    "                                                                 , validation_split, img_rescale, reshaped_size)\n",
    "\n",
    "x_test, y_test = prep_test_data(test_csv_fname, test_folder_name, img_rescale, reshaped_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2b696",
   "metadata": {},
   "source": [
    "# Create the CNN base model\n",
    "\n",
    "#### The functions used in this files will be loaded from \"cnn_functions.py\"\n",
    "\n",
    "- The code for the base model is shown below. \n",
    "- initialise callbacks to be used in training the model\n",
    "- parameters for the image augmentation will be tested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef67a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def created_untuned_model(x_input_shape, output_layer):\n",
    "    \"\"\"\n",
    "    creates a cnn model\n",
    "\n",
    "    Parameters:\n",
    "    x_input_shape (tuple): the shape of the input data\n",
    "    output_layer (int): the number of neurons in the output layer\n",
    "\n",
    "    Returns:\n",
    "    keras model object.\n",
    "    \"\"\"\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, \n",
    "         kernel_size=(3, 3), activation=\"relu\", input_shape=(x_input_shape), kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=initializer))    \n",
    "    model.add(tf.keras.layers.Dense(units=output_layer, activation=\"softmax\", kernel_initializer=initializer))    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52bad7",
   "metadata": {},
   "source": [
    "# Test data image augmentation techniques\n",
    "\n",
    "- based on a quicky look at the images provided in the train and test set, the following data image augmentation methods are chosen with a quick explanation below.\n",
    "\n",
    "\n",
    "rotation_range: the fruits provided in the dataset provided are not always at the same orientation and should be tested with rotations\n",
    "\n",
    "width_shift_range: some of the fruits are not located directly in the centre and shifing the positiona may provide more useful training data\n",
    "\n",
    "height_shift_range:\n",
    "\n",
    "brightness_range:\n",
    "\n",
    "shear_range: \n",
    "\n",
    "zoom_range:\n",
    "\n",
    "horizontal_flip:\n",
    "\n",
    "\n",
    "rotation_range=[0, 30, 60]\n",
    "width_shift_range=[0.0, 0.1, 0.2]\n",
    "height_shift_range=[0.0, 0.1, 0.2]\n",
    "shear_range=[0.0, 0.2, 0.4]\n",
    "zoom_range=[0.0, 0.4, 0.8]\n",
    "horizontal_flip=[False, True]\n",
    "\n",
    "Note that the training methodology is as such.\n",
    "\n",
    "for each parameter, we will test and see if there is an improvement in the validation accuracy on the test data.\n",
    "\n",
    "if there is an improvement, the values will be used to test if the image augmentation helps with the training of the model.\n",
    "\n",
    "in the event no data works, a random combination will be used to check for image data generation. finally the lsit of graphs will be plotted.\n",
    "\n",
    "The baseline of the test accuracy on an untuned model with no data augmentation is shown below:\n",
    "\n",
    "The accuracy of the untuned model on the test dataset is: \n",
    "2/2 [==============================] - 1s 337ms/step - loss: 1.1511 - accuracy: 0.9000\n",
    "[1.1511120796203613, 0.8999999761581421]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3dffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(x_train, y_train, x_val, y_val, batch_size, aug_param):\n",
    "    \"\"\"\n",
    "    augments the training data by performing scaling and data augmentation to generate more data\n",
    "\n",
    "    Parameters:\n",
    "    x_train (np.array): the input training data for the cnn\n",
    "    y_train (np.array): the output training data for the cnn\n",
    "    x_val (np.array): the input validation data for the cnn\n",
    "    y_val (np.array): the input validation data for the cnn\n",
    "\n",
    "\n",
    "    Returns: \n",
    "    tuple: A tuple containing two `tf.keras.preprocessing.image.ImageDataGenerator` objects.\n",
    "    The first object generates batches of augmented training data, the second object generates batches of \n",
    "    validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=0.0, #default: 0\n",
    "        width_shift_range=0.0, #default: 0.0\n",
    "        height_shift_range=0.0, #default: 0.0\n",
    "        shear_range=0.0, #default: 0.0\n",
    "        zoom_range=aug_param, #default: 0.0\n",
    "        horizontal_flip=False\n",
    "        )\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Use the data generator to generate batches of augmented data\n",
    "    train_augment_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "    val_augment_generator = ImageDataGenerator().flow(x_val, y_val, batch_size=batch_size)\n",
    "\n",
    "    return train_augment_generator, val_augment_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4e5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values below for the loop to test\n",
    "\n",
    "# change this for the file name\n",
    "aug_param_name = \"zoom_range\"\n",
    "aug_params = [0.0, 0.4, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfa88e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 15:45:42.360941: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 10s 2s/step - loss: 323.6060 - accuracy: 0.3562 - val_loss: 302.7957 - val_accuracy: 0.3125\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 168.3249 - accuracy: 0.3557 - val_loss: 107.3837 - val_accuracy: 0.3438\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 69.7751 - accuracy: 0.4500 - val_loss: 35.9976 - val_accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 21.1645 - accuracy: 0.5973 - val_loss: 19.7312 - val_accuracy: 0.3438\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 11.6739 - accuracy: 0.6644 - val_loss: 9.5315 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.9409 - accuracy: 0.8062 - val_loss: 6.7289 - val_accuracy: 0.5938\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.5555 - accuracy: 0.7651 - val_loss: 2.2430 - val_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6266 - accuracy: 0.9262 - val_loss: 2.7147 - val_accuracy: 0.8750\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6697 - accuracy: 0.9195 - val_loss: 2.1312 - val_accuracy: 0.8750\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1881 - accuracy: 0.9799 - val_loss: 2.3810 - val_accuracy: 0.8125\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.1705 - accuracy: 0.9463 - val_loss: 2.1104 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.0884 - accuracy: 0.9812 - val_loss: 1.9887 - val_accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.0655 - accuracy: 0.9688 - val_loss: 1.9308 - val_accuracy: 0.9375\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.0349 - accuracy: 0.9866 - val_loss: 2.1314 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 12s 3s/step - loss: 0.0140 - accuracy: 0.9933 - val_loss: 1.8789 - val_accuracy: 0.9062\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 1.9733 - val_accuracy: 0.8438\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 18s 3s/step - loss: 8.4726e-04 - accuracy: 1.0000 - val_loss: 1.8218 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 16s 3s/step - loss: 2.0548e-04 - accuracy: 1.0000 - val_loss: 1.8278 - val_accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 2.1053e-04 - accuracy: 1.0000 - val_loss: 1.8626 - val_accuracy: 0.9062\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 2.8944e-04 - accuracy: 1.0000 - val_loss: 1.8871 - val_accuracy: 0.9062\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 6.0360e-05 - accuracy: 1.0000 - val_loss: 1.9000 - val_accuracy: 0.9062\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 2.4794e-04 - accuracy: 1.0000 - val_loss: 1.9034 - val_accuracy: 0.9062\n",
      "The accuracy of the untuned augmented data model on the test dataset is: \n",
      "2/2 [==============================] - 1s 495ms/step - loss: 0.9123 - accuracy: 0.9167\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 20s 3s/step - loss: 246.1390 - accuracy: 0.3625 - val_loss: 90.1908 - val_accuracy: 0.3125\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 19s 4s/step - loss: 110.5439 - accuracy: 0.3154 - val_loss: 74.5299 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 46.7609 - accuracy: 0.5302 - val_loss: 5.5548 - val_accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 12s 3s/step - loss: 18.0314 - accuracy: 0.5188 - val_loss: 5.2869 - val_accuracy: 0.7188\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 12s 3s/step - loss: 4.9924 - accuracy: 0.7450 - val_loss: 9.7593 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 5.1677 - accuracy: 0.7500 - val_loss: 2.7708 - val_accuracy: 0.7188\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 3.0339 - accuracy: 0.7919 - val_loss: 2.6883 - val_accuracy: 0.7812\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 1.3691 - accuracy: 0.8322 - val_loss: 3.6013 - val_accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.2252 - accuracy: 0.7750 - val_loss: 1.6333 - val_accuracy: 0.8438\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.6485 - accuracy: 0.8591 - val_loss: 0.9621 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.4942 - accuracy: 0.8591 - val_loss: 1.2752 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 12s 2s/step - loss: 0.2419 - accuracy: 0.9195 - val_loss: 1.1956 - val_accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.4270 - accuracy: 0.9262 - val_loss: 1.1271 - val_accuracy: 0.9375\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.1715 - accuracy: 0.9396 - val_loss: 1.0234 - val_accuracy: 0.9062\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 13s 2s/step - loss: 0.1068 - accuracy: 0.9530 - val_loss: 1.0060 - val_accuracy: 0.9062\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.0909 - accuracy: 0.9866 - val_loss: 0.9880 - val_accuracy: 0.9062\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.1101 - accuracy: 0.9597 - val_loss: 1.0621 - val_accuracy: 0.9062\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 17s 4s/step - loss: 0.0441 - accuracy: 0.9933 - val_loss: 1.4330 - val_accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 11s 2s/step - loss: 0.0931 - accuracy: 0.9664 - val_loss: 1.9380 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 1.4263 - val_accuracy: 0.9062\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.0281 - accuracy: 0.9933 - val_loss: 1.3746 - val_accuracy: 0.9062\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.0517 - accuracy: 0.9937 - val_loss: 1.3387 - val_accuracy: 0.9062\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 1.3011 - val_accuracy: 0.9062\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 12s 3s/step - loss: 0.0372 - accuracy: 0.9866 - val_loss: 1.2842 - val_accuracy: 0.9062\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.2854 - val_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 1.2710 - val_accuracy: 0.8750\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 12s 3s/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 1.2562 - val_accuracy: 0.9062\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.2605 - val_accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 13s 3s/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 1.2730 - val_accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 10s 2s/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 1.2830 - val_accuracy: 0.8750\n",
      "The accuracy of the untuned augmented data model on the test dataset is: \n",
      "2/2 [==============================] - 1s 416ms/step - loss: 1.4834 - accuracy: 0.8833\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 23s 5s/step - loss: 307.6682 - accuracy: 0.2953 - val_loss: 201.9149 - val_accuracy: 0.4688\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 17s 3s/step - loss: 158.9094 - accuracy: 0.3960 - val_loss: 150.0712 - val_accuracy: 0.0312\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 69.6313 - accuracy: 0.2750 - val_loss: 11.7097 - val_accuracy: 0.6250\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 22.8191 - accuracy: 0.6309 - val_loss: 10.1435 - val_accuracy: 0.8438\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 17.7620 - accuracy: 0.7812 - val_loss: 7.9704 - val_accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 16.2548 - accuracy: 0.7584 - val_loss: 4.1567 - val_accuracy: 0.9062\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 6.5776 - accuracy: 0.8456 - val_loss: 1.8296 - val_accuracy: 0.9062\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 2.9597 - accuracy: 0.7315 - val_loss: 0.9331 - val_accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.8631 - accuracy: 0.7987 - val_loss: 1.1493 - val_accuracy: 0.8750\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.6621 - accuracy: 0.8255 - val_loss: 0.6588 - val_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7187 - accuracy: 0.8591 - val_loss: 0.6072 - val_accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.7313 - accuracy: 0.8523 - val_loss: 0.6757 - val_accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.5512 - accuracy: 0.8993 - val_loss: 0.7885 - val_accuracy: 0.9062\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3888 - accuracy: 0.8859 - val_loss: 0.8954 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.4475 - accuracy: 0.8926 - val_loss: 0.9202 - val_accuracy: 0.9062\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3758 - accuracy: 0.8993 - val_loss: 0.9197 - val_accuracy: 0.9062\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.4121 - accuracy: 0.9187 - val_loss: 0.8145 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3548 - accuracy: 0.8859 - val_loss: 0.8118 - val_accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2778 - accuracy: 0.9060 - val_loss: 0.8210 - val_accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2786 - accuracy: 0.9060 - val_loss: 0.8039 - val_accuracy: 0.9375\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.3905 - accuracy: 0.9312 - val_loss: 0.8090 - val_accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.4150 - accuracy: 0.9060 - val_loss: 0.9076 - val_accuracy: 0.9062\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2547 - accuracy: 0.9396 - val_loss: 1.5035 - val_accuracy: 0.9375\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2316 - accuracy: 0.9250 - val_loss: 0.8537 - val_accuracy: 0.9062\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1936 - accuracy: 0.9463 - val_loss: 0.9915 - val_accuracy: 0.9062\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2273 - accuracy: 0.9195 - val_loss: 1.0849 - val_accuracy: 0.9062\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1806 - accuracy: 0.9250 - val_loss: 1.2050 - val_accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1561 - accuracy: 0.9530 - val_loss: 1.6061 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2277 - accuracy: 0.9530 - val_loss: 1.0310 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0940 - accuracy: 0.9732 - val_loss: 0.9793 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1502 - accuracy: 0.9530 - val_loss: 0.9704 - val_accuracy: 0.9062\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1208 - accuracy: 0.9530 - val_loss: 1.0237 - val_accuracy: 0.9062\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1043 - accuracy: 0.9799 - val_loss: 1.0674 - val_accuracy: 0.9062\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1364 - accuracy: 0.9396 - val_loss: 1.1445 - val_accuracy: 0.9062\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1232 - accuracy: 0.9375 - val_loss: 1.1222 - val_accuracy: 0.9062\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0700 - accuracy: 0.9866 - val_loss: 1.0666 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.2374 - accuracy: 0.9396 - val_loss: 1.0397 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1620 - accuracy: 0.9463 - val_loss: 1.0876 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0942 - accuracy: 0.9530 - val_loss: 1.1237 - val_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1127 - accuracy: 0.9866 - val_loss: 1.1648 - val_accuracy: 0.8750\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.1030 - accuracy: 0.9799 - val_loss: 1.0947 - val_accuracy: 0.8750\n",
      "The accuracy of the untuned augmented data model on the test dataset is: \n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.8252 - accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "# run a for loop to test\n",
    "\n",
    "# initialise the variables used for hyperparameter tuning\n",
    "# number of epochs is set to 100, and earlystopping is used to reduce overfitting and stop \n",
    "# training automatically when there is not much improvements in the accuracy\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# generate steps per epoch\n",
    "num_of_samples = len(x_train)\n",
    "steps_per_epoch = num_of_samples // batch_size\n",
    "\n",
    "for params in aug_params:\n",
    "    \n",
    "    # augment the data\n",
    "    train_augment_generator, val_augment_generator = augment_data(x_train, y_train, x_val\n",
    "                                                                  , y_val, batch_size, params)\n",
    "    \n",
    "    # Initialise callbacks, earlystopping is used to reduce overfit \n",
    "    earlyStopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", restore_best_weights=True, patience=5)\n",
    "    # Create a csv logger callback and create a unique name for the logger file using datetime\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    data_aug_logger_name = f\"logger/data_aug_params/{aug_param_name}&{params}-{current_time}.log\"\n",
    "    data_aug_logger = tf.keras.callbacks.CSVLogger(data_aug_logger_name, separator=\",\", append=False)\n",
    "\n",
    "    # Create a list of the loggers to fit in the model\n",
    "    aug_data_callbacks = [earlyStopping, data_aug_logger]\n",
    "    \n",
    "    # create the model\n",
    "    aug_data_model = created_untuned_model(x_input_shape, output_layer)\n",
    "    aug_data_history = train_aug_gen_model(aug_data_model, train_augment_generator, batch_size, epochs\n",
    "                                           , aug_data_callbacks, val_augment_generator, steps_per_epoch)\n",
    "    \n",
    "    # test the model\n",
    "    print(\"The accuracy of the untuned augmented data model on the test dataset is: \")\n",
    "    test_results = test_model(aug_data_model, x_test, y_test)\n",
    "    \n",
    "    # save the test results to a csv file\n",
    "    csv_fname = f\"logger/data_aug_params_test_acc/aug_params_test.csv\"\n",
    "\n",
    "    # Assuming you have the following values\n",
    "    param_name = aug_param_name\n",
    "    value = params\n",
    "    loss = test_results[0]\n",
    "    accuracy = test_results[1]\n",
    "\n",
    "    # Open the CSV file in append mode\n",
    "    with open(csv_fname, \"a\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row if the file is empty\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writerow([\"param\", \"value\", \"loss\", \"accuracy\"])\n",
    "\n",
    "        # Write a new entry to the CSV file\n",
    "        writer.writerow([param_name, value, loss, accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999b16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
